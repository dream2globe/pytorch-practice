{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 인공신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.6024]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8804], requires_grad=True)\n",
      "tensor([1.4828], grad_fn=<AddBackward0>)\n",
      "tensor([1.4828], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.])\n",
    "model = nn.Linear(1, 1)  # 입력 node 한 개, 출력 node 한 개\n",
    "\n",
    "print(model.weight) # 랜덤한 값이 설정됨\n",
    "print(model.bias)\n",
    "\n",
    "y = model(x)\n",
    "print(y)\n",
    "\n",
    "y = x @ model.weight + model.bias\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4480],\n",
      "        [ 0.5655],\n",
      "        [-0.8771]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5085, -0.8723, -0.2466], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1425, -0.2715, -0.4800]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1932], requires_grad=True)\n",
      "tensor([-0.9564, -0.3068, -1.1237], grad_fn=<AddBackward0>)\n",
      "tensor([0.2932], grad_fn=<AddBackward0>)\n",
      "tensor([0.2932], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fc1 = nn.Linear(1, 3)\n",
    "fc2 = nn.Linear(3, 1)\n",
    "\n",
    "print(fc1.weight)\n",
    "print(fc1.bias)\n",
    "print(fc2.weight)\n",
    "print(fc2.bias)\n",
    "\n",
    "x = torch.tensor([1.])\n",
    "x = fc1(x)\n",
    "print(x)\n",
    "x = fc2(x)\n",
    "print(x)\n",
    "\n",
    "x = torch.tensor([1.])\n",
    "y = (x@fc1.weight.T+fc1.bias)@fc2.weight.T+fc2.bias\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Linear는 개*채*행*열 에서 \"채\" 형태로 (1D data) 들어오길 기대하는 녀석이다.\n",
    "# 즉, 노드 하나가 곧 한 채널을 의미한다.\n",
    "# 따라서, 데이터 여러 개를 통과시키고 싶다면 개*채의 형태로 줘야 함\n",
    "# 일단, wieght shape 개*채에서 채는 무조건 앞에 챈러 개수와 맞춰야 하는 룰을 설정함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0310], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fc1 = nn.Linear(1, 3)\n",
    "fc2 = nn.Linear(3, 1)\n",
    "\n",
    "model = nn.Sequential(fc1, fc2)\n",
    "x = torch.tensor([1.])\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9686,  1.0229],\n",
      "        [-0.8387,  1.7444],\n",
      "        [ 0.4021,  2.5025],\n",
      "        [-0.7557, -0.9301],\n",
      "        [-0.3789,  0.3056]])\n",
      "tensor([[ 0.6180, -0.3130,  0.0989],\n",
      "        [ 0.6306, -0.4186,  0.0777],\n",
      "        [ 0.4590, -0.4413,  0.0039],\n",
      "        [ 0.4895,  0.0180,  0.1299],\n",
      "        [ 0.4852, -0.1506,  0.0864]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 2)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.Linear(5, 10),\n",
    "    nn.Linear(10, 3)\n",
    ")\n",
    "print(x)\n",
    "print(model(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.4402, -1.0430],\n",
      "           [ 0.7390, -1.8498],\n",
      "           [-0.8796,  0.4701],\n",
      "           [-1.9337, -0.8524],\n",
      "           [ 0.6833,  0.6768]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5828, -0.4236],\n",
      "           [-2.0814, -0.2875],\n",
      "           [-0.8140, -0.2724],\n",
      "           [ 0.5366,  0.1097],\n",
      "           [-0.6774,  0.1332]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3151,  0.0846],\n",
      "           [-1.6751, -0.6262],\n",
      "           [-0.3602, -1.4557],\n",
      "           [-0.4994,  0.7028],\n",
      "           [-0.1657,  0.3837]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1699, -1.2068],\n",
      "           [ 0.4641,  0.7964],\n",
      "           [ 1.9145, -0.6428],\n",
      "           [ 1.1025,  0.7450],\n",
      "           [ 1.1609, -3.1561]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2850, -1.0908],\n",
      "           [-1.2163,  0.2235],\n",
      "           [ 0.0694, -1.8126],\n",
      "           [ 2.0916, -0.2447],\n",
      "           [-0.4010,  0.3874]]],\n",
      "\n",
      "\n",
      "         [[[-0.5592, -1.1089],\n",
      "           [ 0.3010,  1.1065],\n",
      "           [-1.1650, -0.0117],\n",
      "           [ 1.4683, -0.2106],\n",
      "           [-1.4642,  1.5526]]]]])\n",
      "tensor([[[[[ 2.8387e-01,  1.3174e-01,  7.6527e-02],\n",
      "           [ 1.9545e-01,  2.8532e-01,  7.9521e-02],\n",
      "           [ 5.7682e-01, -2.1704e-01,  1.0631e-01],\n",
      "           [ 6.9037e-01, -8.8725e-02,  1.8322e-01],\n",
      "           [ 3.2501e-01, -1.2530e-01,  2.9110e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.8946e-01,  4.3567e-02,  5.6882e-02],\n",
      "           [ 7.4198e-01, -1.9135e-01,  1.7825e-01],\n",
      "           [ 5.3051e-01, -9.2440e-02,  1.1884e-01],\n",
      "           [ 3.2258e-01, -4.5864e-02,  4.7846e-02],\n",
      "           [ 5.2694e-01, -1.4671e-01,  1.0396e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 3.5846e-01, -5.9537e-02,  5.8700e-02],\n",
      "           [ 6.5784e-01, -1.0441e-01,  1.6641e-01],\n",
      "           [ 3.9823e-01,  1.3407e-01,  1.2250e-01],\n",
      "           [ 5.2425e-01, -2.2405e-01,  8.3707e-02],\n",
      "           [ 4.5320e-01, -1.4607e-01,  7.4845e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.7822e-01,  1.0928e-01,  1.0841e-01],\n",
      "           [ 3.6739e-01, -1.6205e-01,  3.6818e-02],\n",
      "           [ 5.6095e-02,  1.8528e-01, -6.0903e-04],\n",
      "           [ 2.5807e-01, -1.0274e-01,  8.1313e-03],\n",
      "           [ 6.2657e-02,  5.2905e-01,  8.7258e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.0757e-01,  1.2701e-01,  8.4766e-02],\n",
      "           [ 6.2146e-01, -2.0431e-01,  1.2719e-01],\n",
      "           [ 3.0932e-01,  2.2581e-01,  1.0996e-01],\n",
      "           [ 4.5377e-02,  1.3546e-01, -1.7220e-02],\n",
      "           [ 4.9276e-01, -1.6547e-01,  8.5736e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.4806e-01,  6.2405e-02,  1.2451e-01],\n",
      "           [ 4.0945e-01, -2.2494e-01,  3.7917e-02],\n",
      "           [ 6.0168e-01, -1.6241e-01,  1.2973e-01],\n",
      "           [ 1.5136e-01,  8.0124e-02,  1.1126e-02],\n",
      "           [ 7.2621e-01, -4.3780e-01,  1.1086e-01]]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 1, 5, 2)  # 마지막 수만 채널로 인식하면 됨\n",
    "print(x)\n",
    "print(model(x))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4202, 0.5203, 0.4760],\n",
      "        [0.4182, 0.5227, 0.4766],\n",
      "        [0.4210, 0.5177, 0.4759],\n",
      "        [0.4182, 0.5160, 0.4774],\n",
      "        [0.4220, 0.5244, 0.4749]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 5)\n",
    "        self.fc2 = nn.Linear(5, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        self.sig3 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sig1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sig2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sig3(x)                \n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "x = torch.randn(5, 2)\n",
    "y = model(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (sig1): Sigmoid()\n",
      "  (sig2): Sigmoid()\n",
      "  (sig3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3501,  0.5127],\n",
      "        [ 0.3681, -0.2958],\n",
      "        [-0.1568, -0.7006],\n",
      "        [-0.4459, -0.0820],\n",
      "        [-0.3342, -0.3811]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3994,  0.3898,  0.3543,  0.3296, -0.0302,  0.1301, -0.1798,  0.3218,\n",
      "        -0.2978, -0.4342], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(2, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5, 10),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(10, 3),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fcn\n",
    "\n",
    "model = MyModel()\n",
    "x = torch.randn(5, 2)\n",
    "y = model(x)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
